{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "690a99e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM,Dense\n",
    "from tensorflow.keras.models import Sequential,load_model\n",
    "from tensorflow.keras.utils import pad_sequences,to_categorical\n",
    "from pickle import dump,load\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f2c6939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sing a song of sixpence, A pocket full of rye. Four and twenty blackbirds, Baked in a pie. When the pie was opened The birds began to sing; Wasn't that a dainty dish, To set before the king. The king was in his counting house, Counting out his money; The queen was in the parlour, Eating bread and honey. The maid was in the garden, Hanging out the clothes, When down came a blackbird And pecked off her nose.\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text = \"Sing a song of sixpence, A pocket full of rye. Four and twenty blackbirds, Baked in a pie. When the pie was opened The birds began to sing; Wasn't that a dainty dish, To set before the king. The king was in his counting house, Counting out his money; The queen was in the parlour, Eating bread and honey. The maid was in the garden, Hanging out the clothes, When down came a blackbird And pecked off her nose.\" \n",
    "raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7badc54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_doc(filename):\n",
    "    file = open(filename,'r')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text\n",
    "def save_doc(lines,filename):\n",
    "    data = '\\n'.join(lines)\n",
    "    file = open(filename,'w')\n",
    "    file.write(data)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38990a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = raw_text.split()\n",
    "raw_text = ' '.join(tokens)\n",
    "length = 10\n",
    "sequences = list()\n",
    "for i in range(length,len(raw_text)):\n",
    "    seq = raw_text[i-length:i+1]\n",
    "    sequences.append(seq)\n",
    "out_filename = 'char/saved.txt'\n",
    "if not os.path.exists(out_filename):\n",
    "    save_doc(sequences,out_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8820ab78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sing a song',\n",
       " 'ing a song ',\n",
       " 'ng a song o',\n",
       " 'g a song of',\n",
       " ' a song of ',\n",
       " 'a song of s',\n",
       " ' song of si',\n",
       " 'song of six',\n",
       " 'ong of sixp',\n",
       " 'ng of sixpe',\n",
       " 'g of sixpen',\n",
       " ' of sixpenc',\n",
       " 'of sixpence',\n",
       " 'f sixpence,',\n",
       " ' sixpence, ',\n",
       " 'sixpence, A',\n",
       " 'ixpence, A ',\n",
       " 'xpence, A p',\n",
       " 'pence, A po',\n",
       " 'ence, A poc']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = out_filename\n",
    "raw_text = load_doc(filename)\n",
    "lines = raw_text.split('\\n')\n",
    "lines[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba9759c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " \"'\": 2,\n",
       " ',': 3,\n",
       " '.': 4,\n",
       " ';': 5,\n",
       " 'A': 6,\n",
       " 'B': 7,\n",
       " 'C': 8,\n",
       " 'E': 9,\n",
       " 'F': 10,\n",
       " 'H': 11,\n",
       " 'S': 12,\n",
       " 'T': 13,\n",
       " 'W': 14,\n",
       " 'a': 15,\n",
       " 'b': 16,\n",
       " 'c': 17,\n",
       " 'd': 18,\n",
       " 'e': 19,\n",
       " 'f': 20,\n",
       " 'g': 21,\n",
       " 'h': 22,\n",
       " 'i': 23,\n",
       " 'k': 24,\n",
       " 'l': 25,\n",
       " 'm': 26,\n",
       " 'n': 27,\n",
       " 'o': 28,\n",
       " 'p': 29,\n",
       " 'q': 30,\n",
       " 'r': 31,\n",
       " 's': 32,\n",
       " 't': 33,\n",
       " 'u': 34,\n",
       " 'w': 35,\n",
       " 'x': 36,\n",
       " 'y': 37}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(raw_text)))\n",
    "mapping = dict((c,i) for i,c in enumerate(chars))\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33bac7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = list()\n",
    "for line in lines:\n",
    "    enc_seq = [mapping[char] for char in line]\n",
    "    sequences.append(enc_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07c1e4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(399, 10)\n",
      "(399, 10, 38)\n",
      "(399, 38)\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(mapping)\n",
    "sequences = np.array(sequences)\n",
    "x,y = sequences[:,:-1],sequences[:,-1]\n",
    "print(x.shape)\n",
    "sequences = [to_categorical(l,num_classes=vocab_size) for l in x]\n",
    "x = np.array(sequences)\n",
    "print(x.shape)\n",
    "y = to_categorical(y,num_classes=vocab_size)\n",
    "y = np.array(y)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83ddd504",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python310\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">34,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,838</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m)             │        \u001b[38;5;34m34,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │         \u001b[38;5;34m7,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m)             │         \u001b[38;5;34m3,838\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">45,638</span> (178.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m45,638\u001b[0m (178.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">45,638</span> (178.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m45,638\u001b[0m (178.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    LSTM(75,input_shape=(x.shape[1],x.shape[2])),\n",
    "    Dense(100,activation='relu'),\n",
    "    Dense(vocab_size,activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f370982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "13/13 - 2s - 171ms/step - accuracy: 0.0727 - loss: 3.6293\n",
      "Epoch 2/150\n",
      "13/13 - 0s - 11ms/step - accuracy: 0.1905 - loss: 3.5573\n",
      "Epoch 3/150\n",
      "13/13 - 0s - 10ms/step - accuracy: 0.1905 - loss: 3.2923\n",
      "Epoch 4/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.1905 - loss: 3.0927\n",
      "Epoch 5/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.1905 - loss: 3.0180\n",
      "Epoch 6/150\n",
      "13/13 - 0s - 14ms/step - accuracy: 0.1905 - loss: 2.9931\n",
      "Epoch 7/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.1905 - loss: 2.9831\n",
      "Epoch 8/150\n",
      "13/13 - 0s - 14ms/step - accuracy: 0.1905 - loss: 2.9591\n",
      "Epoch 9/150\n",
      "13/13 - 0s - 14ms/step - accuracy: 0.1905 - loss: 2.9425\n",
      "Epoch 10/150\n",
      "13/13 - 0s - 13ms/step - accuracy: 0.1905 - loss: 2.9196\n",
      "Epoch 11/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.2306 - loss: 2.8802\n",
      "Epoch 12/150\n",
      "13/13 - 0s - 14ms/step - accuracy: 0.2180 - loss: 2.8486\n",
      "Epoch 13/150\n",
      "13/13 - 0s - 13ms/step - accuracy: 0.2331 - loss: 2.7911\n",
      "Epoch 14/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.2481 - loss: 2.7338\n",
      "Epoch 15/150\n",
      "13/13 - 0s - 11ms/step - accuracy: 0.2732 - loss: 2.6636\n",
      "Epoch 16/150\n",
      "13/13 - 0s - 11ms/step - accuracy: 0.2732 - loss: 2.6034\n",
      "Epoch 17/150\n",
      "13/13 - 0s - 10ms/step - accuracy: 0.3083 - loss: 2.5398\n",
      "Epoch 18/150\n",
      "13/13 - 0s - 10ms/step - accuracy: 0.3083 - loss: 2.4707\n",
      "Epoch 19/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.3308 - loss: 2.4217\n",
      "Epoch 20/150\n",
      "13/13 - 0s - 11ms/step - accuracy: 0.3434 - loss: 2.3365\n",
      "Epoch 21/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.3784 - loss: 2.2665\n",
      "Epoch 22/150\n",
      "13/13 - 0s - 11ms/step - accuracy: 0.3885 - loss: 2.2259\n",
      "Epoch 23/150\n",
      "13/13 - 0s - 13ms/step - accuracy: 0.4010 - loss: 2.1657\n",
      "Epoch 24/150\n",
      "13/13 - 0s - 10ms/step - accuracy: 0.4110 - loss: 2.1338\n",
      "Epoch 25/150\n",
      "13/13 - 0s - 10ms/step - accuracy: 0.4060 - loss: 2.0830\n",
      "Epoch 26/150\n",
      "13/13 - 0s - 11ms/step - accuracy: 0.4135 - loss: 1.9780\n",
      "Epoch 27/150\n",
      "13/13 - 0s - 11ms/step - accuracy: 0.4561 - loss: 1.9349\n",
      "Epoch 28/150\n",
      "13/13 - 0s - 11ms/step - accuracy: 0.4561 - loss: 1.8748\n",
      "Epoch 29/150\n",
      "13/13 - 0s - 10ms/step - accuracy: 0.4586 - loss: 1.8459\n",
      "Epoch 30/150\n",
      "13/13 - 0s - 10ms/step - accuracy: 0.4511 - loss: 1.8200\n",
      "Epoch 31/150\n",
      "13/13 - 0s - 10ms/step - accuracy: 0.5088 - loss: 1.7295\n",
      "Epoch 32/150\n",
      "13/13 - 0s - 10ms/step - accuracy: 0.5288 - loss: 1.6658\n",
      "Epoch 33/150\n",
      "13/13 - 0s - 11ms/step - accuracy: 0.5313 - loss: 1.6210\n",
      "Epoch 34/150\n",
      "13/13 - 0s - 10ms/step - accuracy: 0.5564 - loss: 1.5849\n",
      "Epoch 35/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.5589 - loss: 1.5007\n",
      "Epoch 36/150\n",
      "13/13 - 0s - 11ms/step - accuracy: 0.5739 - loss: 1.4552\n",
      "Epoch 37/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.5789 - loss: 1.4262\n",
      "Epoch 38/150\n",
      "13/13 - 0s - 10ms/step - accuracy: 0.5714 - loss: 1.3957\n",
      "Epoch 39/150\n",
      "13/13 - 0s - 10ms/step - accuracy: 0.5990 - loss: 1.3595\n",
      "Epoch 40/150\n",
      "13/13 - 0s - 10ms/step - accuracy: 0.6065 - loss: 1.3019\n",
      "Epoch 41/150\n",
      "13/13 - 0s - 10ms/step - accuracy: 0.6617 - loss: 1.2176\n",
      "Epoch 42/150\n",
      "13/13 - 0s - 13ms/step - accuracy: 0.6642 - loss: 1.1528\n",
      "Epoch 43/150\n",
      "13/13 - 0s - 13ms/step - accuracy: 0.6942 - loss: 1.0856\n",
      "Epoch 44/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.6842 - loss: 1.0688\n",
      "Epoch 45/150\n",
      "13/13 - 0s - 13ms/step - accuracy: 0.7243 - loss: 1.0078\n",
      "Epoch 46/150\n",
      "13/13 - 0s - 13ms/step - accuracy: 0.7594 - loss: 0.9402\n",
      "Epoch 47/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.7469 - loss: 0.9149\n",
      "Epoch 48/150\n",
      "13/13 - 0s - 14ms/step - accuracy: 0.7519 - loss: 0.9012\n",
      "Epoch 49/150\n",
      "13/13 - 0s - 13ms/step - accuracy: 0.7494 - loss: 0.8537\n",
      "Epoch 50/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.7744 - loss: 0.8172\n",
      "Epoch 51/150\n",
      "13/13 - 0s - 15ms/step - accuracy: 0.8020 - loss: 0.7332\n",
      "Epoch 52/150\n",
      "13/13 - 0s - 15ms/step - accuracy: 0.8371 - loss: 0.6920\n",
      "Epoch 53/150\n",
      "13/13 - 0s - 17ms/step - accuracy: 0.8396 - loss: 0.6497\n",
      "Epoch 54/150\n",
      "13/13 - 0s - 13ms/step - accuracy: 0.8421 - loss: 0.6292\n",
      "Epoch 55/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.8496 - loss: 0.6096\n",
      "Epoch 56/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.8672 - loss: 0.5878\n",
      "Epoch 57/150\n",
      "13/13 - 0s - 11ms/step - accuracy: 0.8546 - loss: 0.5680\n",
      "Epoch 58/150\n",
      "13/13 - 0s - 10ms/step - accuracy: 0.8897 - loss: 0.5163\n",
      "Epoch 59/150\n",
      "13/13 - 0s - 11ms/step - accuracy: 0.8872 - loss: 0.5156\n",
      "Epoch 60/150\n",
      "13/13 - 0s - 13ms/step - accuracy: 0.8672 - loss: 0.5168\n",
      "Epoch 61/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.9048 - loss: 0.4588\n",
      "Epoch 62/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.9323 - loss: 0.4080\n",
      "Epoch 63/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.9499 - loss: 0.3579\n",
      "Epoch 64/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.9624 - loss: 0.3214\n",
      "Epoch 65/150\n",
      "13/13 - 0s - 13ms/step - accuracy: 0.9624 - loss: 0.3089\n",
      "Epoch 66/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.9825 - loss: 0.2763\n",
      "Epoch 67/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.9749 - loss: 0.2587\n",
      "Epoch 68/150\n",
      "13/13 - 0s - 15ms/step - accuracy: 0.9850 - loss: 0.2406\n",
      "Epoch 69/150\n",
      "13/13 - 0s - 11ms/step - accuracy: 0.9950 - loss: 0.2193\n",
      "Epoch 70/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.9875 - loss: 0.2134\n",
      "Epoch 71/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.9925 - loss: 0.2012\n",
      "Epoch 72/150\n",
      "13/13 - 0s - 14ms/step - accuracy: 0.9900 - loss: 0.1895\n",
      "Epoch 73/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.9925 - loss: 0.1834\n",
      "Epoch 74/150\n",
      "13/13 - 0s - 11ms/step - accuracy: 0.9925 - loss: 0.1619\n",
      "Epoch 75/150\n",
      "13/13 - 0s - 13ms/step - accuracy: 0.9900 - loss: 0.1544\n",
      "Epoch 76/150\n",
      "13/13 - 0s - 14ms/step - accuracy: 0.9950 - loss: 0.1466\n",
      "Epoch 77/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.9925 - loss: 0.1324\n",
      "Epoch 78/150\n",
      "13/13 - 0s - 11ms/step - accuracy: 0.9925 - loss: 0.1355\n",
      "Epoch 79/150\n",
      "13/13 - 0s - 13ms/step - accuracy: 0.9925 - loss: 0.1262\n",
      "Epoch 80/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.9950 - loss: 0.1134\n",
      "Epoch 81/150\n",
      "13/13 - 0s - 13ms/step - accuracy: 0.9900 - loss: 0.1053\n",
      "Epoch 82/150\n",
      "13/13 - 0s - 13ms/step - accuracy: 0.9950 - loss: 0.1000\n",
      "Epoch 83/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.9925 - loss: 0.1060\n",
      "Epoch 84/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.9950 - loss: 0.0967\n",
      "Epoch 85/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.9900 - loss: 0.0930\n",
      "Epoch 86/150\n",
      "13/13 - 0s - 14ms/step - accuracy: 0.9925 - loss: 0.0824\n",
      "Epoch 87/150\n",
      "13/13 - 0s - 14ms/step - accuracy: 0.9925 - loss: 0.0773\n",
      "Epoch 88/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.9950 - loss: 0.0703\n",
      "Epoch 89/150\n",
      "13/13 - 0s - 13ms/step - accuracy: 0.9950 - loss: 0.0690\n",
      "Epoch 90/150\n",
      "13/13 - 0s - 13ms/step - accuracy: 0.9900 - loss: 0.0691\n",
      "Epoch 91/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.9950 - loss: 0.0637\n",
      "Epoch 92/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.9900 - loss: 0.0630\n",
      "Epoch 93/150\n",
      "13/13 - 0s - 11ms/step - accuracy: 0.9950 - loss: 0.0622\n",
      "Epoch 94/150\n",
      "13/13 - 0s - 11ms/step - accuracy: 0.9950 - loss: 0.0562\n",
      "Epoch 95/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.9950 - loss: 0.0549\n",
      "Epoch 96/150\n",
      "13/13 - 0s - 13ms/step - accuracy: 0.9950 - loss: 0.0528\n",
      "Epoch 97/150\n",
      "13/13 - 0s - 13ms/step - accuracy: 0.9950 - loss: 0.0514\n",
      "Epoch 98/150\n",
      "13/13 - 0s - 11ms/step - accuracy: 0.9925 - loss: 0.0485\n",
      "Epoch 99/150\n",
      "13/13 - 0s - 10ms/step - accuracy: 0.9900 - loss: 0.0461\n",
      "Epoch 100/150\n",
      "13/13 - 0s - 10ms/step - accuracy: 0.9950 - loss: 0.0445\n",
      "Epoch 101/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.9925 - loss: 0.0495\n",
      "Epoch 102/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.9950 - loss: 0.0430\n",
      "Epoch 103/150\n",
      "13/13 - 0s - 11ms/step - accuracy: 0.9925 - loss: 0.0426\n",
      "Epoch 104/150\n",
      "13/13 - 0s - 14ms/step - accuracy: 0.9925 - loss: 0.0396\n",
      "Epoch 105/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.9950 - loss: 0.0399\n",
      "Epoch 106/150\n",
      "13/13 - 0s - 10ms/step - accuracy: 0.9925 - loss: 0.0386\n",
      "Epoch 107/150\n",
      "13/13 - 0s - 11ms/step - accuracy: 0.9925 - loss: 0.0373\n",
      "Epoch 108/150\n",
      "13/13 - 0s - 10ms/step - accuracy: 0.9900 - loss: 0.0413\n",
      "Epoch 109/150\n",
      "13/13 - 0s - 11ms/step - accuracy: 0.9950 - loss: 0.0336\n",
      "Epoch 110/150\n",
      "13/13 - 0s - 10ms/step - accuracy: 0.9925 - loss: 0.0336\n",
      "Epoch 111/150\n",
      "13/13 - 0s - 11ms/step - accuracy: 0.9950 - loss: 0.0362\n",
      "Epoch 112/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.9950 - loss: 0.0360\n",
      "Epoch 113/150\n",
      "13/13 - 0s - 11ms/step - accuracy: 0.9925 - loss: 0.0363\n",
      "Epoch 114/150\n",
      "13/13 - 0s - 11ms/step - accuracy: 0.9900 - loss: 0.0324\n",
      "Epoch 115/150\n",
      "13/13 - 0s - 11ms/step - accuracy: 0.9925 - loss: 0.0302\n",
      "Epoch 116/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.9950 - loss: 0.0313\n",
      "Epoch 117/150\n",
      "13/13 - 0s - 11ms/step - accuracy: 0.9925 - loss: 0.0296\n",
      "Epoch 118/150\n",
      "13/13 - 0s - 11ms/step - accuracy: 0.9900 - loss: 0.0328\n",
      "Epoch 119/150\n",
      "13/13 - 0s - 10ms/step - accuracy: 0.9950 - loss: 0.0282\n",
      "Epoch 120/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.9975 - loss: 0.0239\n",
      "Epoch 121/150\n",
      "13/13 - 0s - 13ms/step - accuracy: 0.9925 - loss: 0.0305\n",
      "Epoch 122/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.9950 - loss: 0.0276\n",
      "Epoch 123/150\n",
      "13/13 - 0s - 11ms/step - accuracy: 0.9925 - loss: 0.0305\n",
      "Epoch 124/150\n",
      "13/13 - 0s - 11ms/step - accuracy: 0.9925 - loss: 0.0250\n",
      "Epoch 125/150\n",
      "13/13 - 0s - 11ms/step - accuracy: 0.9950 - loss: 0.0282\n",
      "Epoch 126/150\n",
      "13/13 - 0s - 11ms/step - accuracy: 0.9925 - loss: 0.0301\n",
      "Epoch 127/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.9925 - loss: 0.0271\n",
      "Epoch 128/150\n",
      "13/13 - 0s - 11ms/step - accuracy: 0.9900 - loss: 0.0252\n",
      "Epoch 129/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.9925 - loss: 0.0242\n",
      "Epoch 130/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.9925 - loss: 0.0232\n",
      "Epoch 131/150\n",
      "13/13 - 0s - 18ms/step - accuracy: 0.9925 - loss: 0.0224\n",
      "Epoch 132/150\n",
      "13/13 - 0s - 13ms/step - accuracy: 0.9925 - loss: 0.0236\n",
      "Epoch 133/150\n",
      "13/13 - 0s - 11ms/step - accuracy: 0.9925 - loss: 0.0240\n",
      "Epoch 134/150\n",
      "13/13 - 0s - 11ms/step - accuracy: 0.9950 - loss: 0.0212\n",
      "Epoch 135/150\n",
      "13/13 - 0s - 11ms/step - accuracy: 0.9900 - loss: 0.0216\n",
      "Epoch 136/150\n",
      "13/13 - 0s - 11ms/step - accuracy: 0.9950 - loss: 0.0210\n",
      "Epoch 137/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.9925 - loss: 0.0203\n",
      "Epoch 138/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.9900 - loss: 0.0239\n",
      "Epoch 139/150\n",
      "13/13 - 0s - 11ms/step - accuracy: 0.9925 - loss: 0.0201\n",
      "Epoch 140/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.9950 - loss: 0.0187\n",
      "Epoch 141/150\n",
      "13/13 - 0s - 11ms/step - accuracy: 0.9925 - loss: 0.0205\n",
      "Epoch 142/150\n",
      "13/13 - 0s - 11ms/step - accuracy: 0.9900 - loss: 0.0200\n",
      "Epoch 143/150\n",
      "13/13 - 0s - 10ms/step - accuracy: 0.9950 - loss: 0.0198\n",
      "Epoch 144/150\n",
      "13/13 - 0s - 11ms/step - accuracy: 0.9950 - loss: 0.0276\n",
      "Epoch 145/150\n",
      "13/13 - 0s - 13ms/step - accuracy: 0.9950 - loss: 0.0239\n",
      "Epoch 146/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.9950 - loss: 0.0197\n",
      "Epoch 147/150\n",
      "13/13 - 0s - 11ms/step - accuracy: 0.9950 - loss: 0.0191\n",
      "Epoch 148/150\n",
      "13/13 - 0s - 11ms/step - accuracy: 0.9925 - loss: 0.0207\n",
      "Epoch 149/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.9950 - loss: 0.0183\n",
      "Epoch 150/150\n",
      "13/13 - 0s - 12ms/step - accuracy: 0.9950 - loss: 0.0203\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x20fca3ce650>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x,y,epochs=150,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0c2be71",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('char/model.keras'):\n",
    "    model.save('char/model.keras')\n",
    "if not os.path.exists('char/mapping.pkl'):\n",
    "    dump(mapping,open('char/mapping.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d2392cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_seq(model,mapping,seq_length,seed_text,n_chars):\n",
    "    in_text = seed_text\n",
    "    for _ in range(n_chars):\n",
    "        encoded = [mapping[char] for char in in_text]\n",
    "        encoded = pad_sequences([encoded],maxlen=seq_length,truncating='pre')\n",
    "        encoded = to_categorical(encoded,num_classes=vocab_size)\n",
    "        ypred = model.predict(encoded,verbose=0)\n",
    "        ypred = np.argmax(ypred)\n",
    "        out_char = ''\n",
    "        for char, index in mapping.items():\n",
    "            if index == ypred:\n",
    "                out_char = char\n",
    "                break\n",
    "        in_text += out_char\n",
    "    return in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c2eceb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('char/model.keras')\n",
    "mapping = load(open('char/mapping.pkl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadfe75c",
   "metadata": {},
   "source": [
    "start of rhyme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44e7dc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sing a song of sixpence, A poc\n"
     ]
    }
   ],
   "source": [
    "print(generate_seq(model,mapping,10,'Sing a son',20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c9c80e",
   "metadata": {},
   "source": [
    "mid of rhyme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "583e2ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A pocket full of rye. Four and twent\n",
      " The king was in his counting house,\n"
     ]
    }
   ],
   "source": [
    "print(generate_seq(model,mapping,10,'A pocket full of',20))\n",
    "print(generate_seq(model,mapping,10,' The king was in',20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee38126",
   "metadata": {},
   "source": [
    "test example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9be48dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "welcome to helrlf ouenty he uoo\n"
     ]
    }
   ],
   "source": [
    "print(generate_seq(model,mapping,10,'welcome to ',20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
